{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# nn contains all of PyTorch's building blocks for neural networks\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "learning_rate = 0.01\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=False, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, b1 = torch.randn(200, 784, requires_grad=True), torch.zeros(200, requires_grad=True)\n",
    "w2, b2 = torch.randn(200, 200, requires_grad=True), torch.zeros(200, requires_grad=True)\n",
    "w3, b3 = torch.randn(10, 200, requires_grad=True), torch.zeros(10, requires_grad=True)\n",
    "\n",
    "### init data\n",
    "torch.nn.init.kaiming_uniform_(w1)\n",
    "torch.nn.init.kaiming_uniform_(w2)\n",
    "torch.nn.init.kaiming_uniform_(w3)\n",
    "\n",
    "def forward(x):\n",
    "    x = x @ w1.T + b1\n",
    "    x = F.relu(x)\n",
    "    x = x @ w2.T + b2\n",
    "    x = F.relu(x)\n",
    "    x = x @ w3.T + b3\n",
    "    x = F.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.713653\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 0.963295\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.565268\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 7878/10000 (79%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.522572\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.759308\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.693554\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 8107/10000 (81%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.575207\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.475329\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.386313\n",
      "\n",
      "Test set: Average loss: 0.0025, Accuracy: 8188/10000 (82%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.363769\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.556574\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.432423\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 8257/10000 (83%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.534446\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.416539\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.396977\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 8303/10000 (83%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.472740\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.490468\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.465250\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8352/10000 (84%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.503606\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.468469\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.408824\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 8370/10000 (84%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.368847\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.475820\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.468482\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 8394/10000 (84%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.386428\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.439223\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.439181\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 8410/10000 (84%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.473185\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.422340\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.402780\n",
      "\n",
      "Test set: Average loss: 0.0021, Accuracy: 8429/10000 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD([w1, b1, w2, b2, w3, b3], lr=learning_rate)\n",
    "criteon = nn.CrossEntropyLoss()\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (x, target) in enumerate(train_loader):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y = forward(x)\n",
    "        loss = criteon(y, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0: \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(x), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data = data.view(data.size(0), -1)\n",
    "        y = forward(data)\n",
    "        test_loss += criteon(y, target).item()\n",
    "        pred = y.data.max(1)[1]\n",
    "        correct += pred.eq(target.data).cpu().sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
